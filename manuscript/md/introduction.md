Behavior is guided to a considerable extent by the environment. Imagine walking on a beach, when an approaching object suddenly grabs your attention [@FranconeriSimons2003]. Without thinking, you reflexively evade the object. Only afterwards do you realize that the approaching object was a volleyball, and that your evasive maneuver has saved you a headache. In situations such as these, behavior is directly based on salient properties of the environment, movement in this case, which automatically attract your attention and elicit a response. This type of bottom-up control allows you to respond quickly and adaptively to relevant stimuli in the environment.

But bottom-up control does not address all challenges of our modern environment equally well. Some situations require a more in-depth, top-down analysis. For example, during driving you must pay attention to things that are not very salient, but nevertheless very relevant [the rear-view mirror, accelerometer, pedestrians, etc., @Recarte2003]. Radiologists, who face the challenge of identifying rare and low-salient patterns in medical images [@Wolfe2010CurrBiol], provide an even more extreme example. In neither of these situation, purely bottom-up control will lead to adaptive behavior. Therefore, it is important to understand the relationship between bottom-up and top-down control. Which factors determine whether top-down or bottom-up control prevails in a particular situation? And is it possible to track the goal-drivenness of behavior as it unfolds?

Van Zoest, Donk, and Theeuwes [-@Van+zoestDonkTheeuwes2004]+[; see also @DonkVan+zoest2008;@SieboldVan+zoestDonk2011;@Van+zoestDonk2005;@Van+zoestDonk2006;@Van+zoestDonk2008] addressed these questions by considering the time-course of visual selection. In one experiment [Exp. 4; @Van+zoestDonkTheeuwes2004], participants searched for a pre-specified target, which was a line-segment tilted 45° from a vertical orientation. The target was embedded in a field of homogeneous vertical line-segments. In addition, a distractor was presented, which was also a tilted line-segment. Crucially, the distractor was either more salient than the target, equally salient, or less salient. The results were clear-cut. Very fast eye movements (with a latency of less than 250 ms) overwhelmingly landed on the most salient object, regardless of whether it was the target or the distractor. In contrast, slow eye movements were usually directed at the target stimulus, regardless of the saliency of the distractor. This suggests that fast eye movements are driven primarily by bottom-up saliency, whereas slow eye movements are driven primarily by top-down goals.

The findings of Van Zoest and colleagues [-@Van+zoestDonkTheeuwes2004]+[; @DonkVan+zoest2008;@SieboldVan+zoestDonk2011;@Van+zoestDonk2005;@Van+zoestDonk2006;@Van+zoestDonk2008]+[; see also @GodijnTheeuwes2002] suggest that bottom-up saliency is dominant in guiding the eyes 'early on' (i.e. for very fast eye movements and/ or immediately after a stimulus has appeared), but that top-down goals become dominant later in time [@FoulshamUnderwood2007;@HendersonMalcolmSchandl2009]. What we propose here is that 'mental effort' is required to exert top-down control. We use the term mental effort in connection with the pupillometry literature [cf. @Beatty1982], but what we suggest specifically is the following. It is computationally non-trivial to evaluate visual input in terms of top-down goals, because goals are abstract concepts that cannot be mapped directly onto visual features [except relatively simple goals, such as "looking for something red", cf. @Wolfe1994]. Presumably, this process takes time [cf. @Van+zoestDonkTheeuwes2004] and requires feedback loops between the early visual system and higher-order parietal and frontal areas [@LammeRoelfsema2000]. In this sense, mental effort is required, even though the computations that underlie top-down guidance may be wholly or partly implicit. Crucially, the amount of effort that we invest in eye-movement guidance is likely to fluctuate over time. For example, participants in a search-for-Waldo experiment [e.g., @KleinMacinnes1999] may initially invest a lot of effort in trying to find Waldo. But over the course of many trials drowsiness sets in and effort wanes. At this point, participants let their eyes glaze over the image, from one conspicuous element to the next, no longer engaging the top-down goal to find Waldo.

Mental effort, as we have described it above, is easily measured. As numerous studies have shown, the pupil faithfully dilates when you engage in a task that in some way requires mental effort [for a recent review, see @LaengSiroisGredebäck2012]+[; for a classic, but remarkably insightful review, see @Loewenfeld1958]: The seminal studies by @KahnemanBeatty1966 have shown that the pupil dilates as a result of increased working memory load; Pupil dilation indicates the amount of effort invested in speech comprehension [@ZekveldKramerFesten2010]; More recently, and more directly related to the present study, it has been shown that pupillary dilation accompanies the detection of a target in a Rapid Serial Visual Presentation (RSVP) paradigm [@PriviteraRenningerCarneyKleinAguilar2010], and that pupil-size indicates search difficulty in a visual search task [@PorterTrosciankoGilchrist2007].

In the present experiments, we measured pupil size while participants viewed an image and made unconstrained eye movements. We consistently found that the pupil was relatively dilated, reflecting increased mental effort [cf. @Beatty1982;@KahnemanBeatty1966;@ZekveldKramerFesten2010], when participants fixated on low-salient locations. We interpret this finding as showing that top-down control in eye-movement guidance relies on mental effort. Without mental effort, or if effort is invested elsewhere, the eyes are captured by high-salient objects, regardless of whether these are relevant to current goals.
